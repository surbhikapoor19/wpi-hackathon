{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåä Massachusetts Water Quality Analysis - Watershed Preservation Opportunity Map\n",
    "\n",
    "## Comprehensive Exploratory Data Analysis\n",
    "\n",
    "This notebook provides extensive visual analysis of Massachusetts water quality data to identify conservation priorities, stormwater stress indicators, and ecosystem instability patterns.\n",
    "\n",
    "### üéØ Analysis Objectives:\n",
    "1. Identify water quality hotspots for conservation\n",
    "2. Detect stormwater stress indicators (high conductivity & TDS)\n",
    "3. Find areas with unstable DO and pH levels\n",
    "4. Map stations with repeated problems\n",
    "5. Create actionable insights for land preservation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Mapping\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print('‚úÖ All libraries loaded successfully!')\n",
    "print(f'üìÖ Analysis Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the water quality data\n",
    "df = pd.read_csv('/mnt/user-data/uploads/sample_water_quality.csv')\n",
    "\n",
    "# Convert date columns\n",
    "df['Sample_Date'] = pd.to_datetime(df['Sample_Date'], errors='coerce')\n",
    "df['Quality_Control_Date'] = pd.to_datetime(df['Quality_Control_Date'], errors='coerce')\n",
    "\n",
    "# Add temporal features\n",
    "df['Year'] = df['Sample_Date'].dt.year\n",
    "df['Month'] = df['Sample_Date'].dt.month\n",
    "df['Month_Name'] = df['Sample_Date'].dt.strftime('%B')\n",
    "df['Season'] = df['Sample_Date'].dt.month%12 // 3 + 1\n",
    "df['Season_Name'] = df['Season'].map({1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'})\n",
    "\n",
    "print(f\"‚úÖ Data loaded: {df.shape[0]:,} records, {df.shape[1]} columns\")\n",
    "print(f\"üìÖ Date range: {df['Sample_Date'].min().date()} to {df['Sample_Date'].max().date()}\")\n",
    "print(f\"üìç Unique stations: {df['Station_ID'].nunique()}\")\n",
    "print(f\"üíß Watersheds: {df['Watershed_Name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Data Overview & Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview statistics\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Records: {len(df):,}\")\n",
    "print(f\"Years Covered: {df['Year'].nunique()} ({df['Year'].min()} - {df['Year'].max()})\")\n",
    "print(f\"\\nüó∫Ô∏è Geographic Coverage:\")\n",
    "print(f\"  ‚Ä¢ Unique Stations: {df['Station_ID'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Watersheds: {df['Watershed_Name'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Water Bodies: {df['Water_Body_Name'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Latitude Range: {df['Latitude'].min():.4f} to {df['Latitude'].max():.4f}\")\n",
    "print(f\"  ‚Ä¢ Longitude Range: {df['Longitude'].min():.4f} to {df['Longitude'].max():.4f}\")\n",
    "print(f\"\\nüìà Sampling Statistics:\")\n",
    "print(f\"  ‚Ä¢ Average samples per station: {df.groupby('Station_ID').size().mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Max samples at one station: {df.groupby('Station_ID').size().max()}\")\n",
    "print(f\"  ‚Ä¢ Stations with >50 samples: {(df.groupby('Station_ID').size() > 50).sum()}\")\n",
    "\n",
    "# Top watersheds by sample count\n",
    "print(f\"\\nüèÜ Top 5 Watersheds by Sample Count:\")\n",
    "top_watersheds = df['Watershed_Name'].value_counts().head(5)\n",
    "for watershed, count in top_watersheds.items():\n",
    "    print(f\"  ‚Ä¢ {watershed}: {count:,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data completeness visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=(\n",
    "        'Records by Year',\n",
    "        'Top 10 Watersheds',\n",
    "        'Data Completeness (%)',\n",
    "        'Samples per Station',\n",
    "        'Monthly Sampling Pattern',\n",
    "        'Seasonal Distribution'\n",
    "    ),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}, {'type': 'bar'}],\n",
    "           [{'type': 'histogram'}, {'type': 'scatter'}, {'type': 'pie'}]]\n",
    ")\n",
    "\n",
    "# 1. Records by year\n",
    "yearly_counts = df.groupby('Year').size()\n",
    "fig.add_trace(\n",
    "    go.Bar(x=yearly_counts.index, y=yearly_counts.values,\n",
    "           marker_color='steelblue', text=yearly_counts.values,\n",
    "           textposition='outside'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Top watersheds\n",
    "watershed_counts = df['Watershed_Name'].value_counts().head(10)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=watershed_counts.values, y=watershed_counts.index,\n",
    "           orientation='h', marker_color='teal',\n",
    "           text=watershed_counts.values),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Data completeness\n",
    "params = ['Temperature_C_Numeric', 'pH_Level_Numeric', 'Dissolved_Oxygen_Numeric', \n",
    "          'Specific_Conductivity_Numeric', 'Total_Dissolved_Solids_Numeric']\n",
    "completeness = []\n",
    "param_names = ['Temperature', 'pH', 'DO', 'Conductivity', 'TDS']\n",
    "for param in params:\n",
    "    if param in df.columns:\n",
    "        completeness.append((df[param].notna().sum()/len(df))*100)\n",
    "    else:\n",
    "        completeness.append(0)\n",
    "\n",
    "colors = ['green' if c > 80 else 'yellow' if c > 60 else 'red' for c in completeness]\n",
    "fig.add_trace(\n",
    "    go.Bar(x=param_names, y=completeness, marker_color=colors,\n",
    "           text=[f'{c:.1f}%' for c in completeness], textposition='outside'),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "# 4. Samples per station distribution\n",
    "station_samples = df.groupby('Station_ID').size()\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=station_samples.values, nbinsx=30,\n",
    "                marker_color='coral'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 5. Monthly pattern\n",
    "monthly_counts = df.groupby('Month').size()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=month_names, y=monthly_counts.values,\n",
    "              mode='lines+markers', line=dict(color='purple', width=2),\n",
    "              marker=dict(size=8)),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# 6. Seasonal distribution\n",
    "seasonal_counts = df['Season_Name'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=seasonal_counts.index, values=seasonal_counts.values,\n",
    "          marker=dict(colors=['lightblue', 'lightgreen', 'yellow', 'orange'])),\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "fig.update_layout(height=700, showlegend=False,\n",
    "                 title_text=\"<b>Water Quality Dataset Overview</b>\",\n",
    "                 title_font_size=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Geographic Distribution of Monitoring Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create station location map\n",
    "station_locations = df.groupby('Station_ID').agg({\n",
    "    'Latitude': 'first',\n",
    "    'Longitude': 'first',\n",
    "    'Watershed_Name': 'first',\n",
    "    'Water_Body_Name': 'first',\n",
    "    'Station_ID': 'size'\n",
    "}).rename(columns={'Station_ID': 'Sample_Count'})\n",
    "\n",
    "fig = px.scatter_mapbox(\n",
    "    station_locations,\n",
    "    lat='Latitude',\n",
    "    lon='Longitude',\n",
    "    color='Watershed_Name',\n",
    "    size='Sample_Count',\n",
    "    hover_name=station_locations.index,\n",
    "    hover_data={'Water_Body_Name': True, 'Sample_Count': True, 'Watershed_Name': True},\n",
    "    title='<b>Water Quality Monitoring Stations Across Massachusetts</b>',\n",
    "    mapbox_style='carto-positron',\n",
    "    zoom=7,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    mapbox=dict(\n",
    "        center=dict(\n",
    "            lat=station_locations['Latitude'].mean(),\n",
    "            lon=station_locations['Longitude'].mean()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"üìç Total monitoring stations mapped: {len(station_locations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Water Quality Parameter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter summary statistics\n",
    "params = ['Temperature_C_Numeric', 'pH_Level_Numeric', 'Dissolved_Oxygen_Numeric',\n",
    "          'Specific_Conductivity_Numeric', 'Total_Dissolved_Solids_Numeric', \n",
    "          'Dissolved_Oxygen_Saturation_Numeric']\n",
    "\n",
    "print(\"üìä WATER QUALITY PARAMETER STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for param in params:\n",
    "    if param in df.columns:\n",
    "        data = df[param].dropna()\n",
    "        summary_data.append({\n",
    "            'Parameter': param.replace('_Numeric', '').replace('_', ' '),\n",
    "            'Count': len(data),\n",
    "            'Mean': data.mean(),\n",
    "            'Std': data.std(),\n",
    "            'Min': data.min(),\n",
    "            '25%': data.quantile(0.25),\n",
    "            'Median': data.median(),\n",
    "            '75%': data.quantile(0.75),\n",
    "            'Max': data.max()\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.round(2)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter distribution plots with thresholds\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Water Quality Parameter Distributions with EPA Thresholds', fontsize=14, y=1.02)\n",
    "\n",
    "# Parameter configurations\n",
    "plot_configs = [\n",
    "    ('Temperature_C_Numeric', 'Temperature (¬∞C)', axes[0,0], None, None, 'blue'),\n",
    "    ('pH_Level_Numeric', 'pH', axes[0,1], 6.5, 8.5, 'green'),\n",
    "    ('Dissolved_Oxygen_Numeric', 'DO (mg/L)', axes[0,2], 5, None, 'cyan'),\n",
    "    ('Specific_Conductivity_Numeric', 'Conductivity (¬µS/cm)', axes[1,0], None, 500, 'orange'),\n",
    "    ('Total_Dissolved_Solids_Numeric', 'TDS (mg/L)', axes[1,1], None, 500, 'brown'),\n",
    "    ('Dissolved_Oxygen_Saturation_Numeric', 'DO Saturation (%)', axes[1,2], 60, None, 'purple')\n",
    "]\n",
    "\n",
    "for param, label, ax, low_thresh, high_thresh, color in plot_configs:\n",
    "    if param in df.columns:\n",
    "        data = df[param].dropna()\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            # Histogram\n",
    "            ax.hist(data, bins=40, density=True, alpha=0.6, color=color, edgecolor='black')\n",
    "            \n",
    "            # Statistics lines\n",
    "            ax.axvline(data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {data.mean():.1f}')\n",
    "            ax.axvline(data.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {data.median():.1f}')\n",
    "            \n",
    "            # Threshold lines and unsafe zones\n",
    "            if param == 'pH_Level_Numeric' and low_thresh and high_thresh:\n",
    "                ax.axvspan(data.min(), low_thresh, alpha=0.2, color='red')\n",
    "                ax.axvspan(high_thresh, data.max(), alpha=0.2, color='red')\n",
    "                ax.axvline(low_thresh, color='red', linestyle=':', linewidth=2)\n",
    "                ax.axvline(high_thresh, color='red', linestyle=':', linewidth=2)\n",
    "            elif param == 'Dissolved_Oxygen_Numeric' and low_thresh:\n",
    "                ax.axvspan(data.min(), low_thresh, alpha=0.2, color='red')\n",
    "                ax.axvline(low_thresh, color='red', linestyle=':', linewidth=2, label=f'Critical: {low_thresh}')\n",
    "            elif high_thresh:\n",
    "                ax.axvspan(high_thresh, data.max(), alpha=0.2, color='red')\n",
    "                ax.axvline(high_thresh, color='red', linestyle=':', linewidth=2, label=f'Max Safe: {high_thresh}')\n",
    "            \n",
    "            ax.set_xlabel(label)\n",
    "            ax.set_ylabel('Density')\n",
    "            ax.set_title(f'{label} (n={len(data):,})')\n",
    "            ax.legend(loc='best', fontsize=8)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Stormwater Stress Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate stormwater stress metrics\n",
    "stress_metrics = df.groupby('Station_ID').agg({\n",
    "    'Specific_Conductivity_Numeric': ['mean', 'max', 'std', 'count'],\n",
    "    'Total_Dissolved_Solids_Numeric': ['mean', 'max', 'std'],\n",
    "    'Latitude': 'first',\n",
    "    'Longitude': 'first',\n",
    "    'Watershed_Name': 'first'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "stress_metrics.columns = ['_'.join(col).strip() for col in stress_metrics.columns.values]\n",
    "stress_metrics = stress_metrics.reset_index()\n",
    "\n",
    "# Calculate stress scores (EPA thresholds: 500 ¬µS/cm for conductivity, 500 mg/L for TDS)\n",
    "stress_metrics['conductivity_stress'] = (stress_metrics['Specific_Conductivity_Numeric_mean'] / 500).clip(0, 2)\n",
    "stress_metrics['tds_stress'] = (stress_metrics['Total_Dissolved_Solids_Numeric_mean'] / 500).clip(0, 2)\n",
    "stress_metrics['stormwater_stress_score'] = (stress_metrics['conductivity_stress'] + stress_metrics['tds_stress']) / 2\n",
    "\n",
    "# Categorize stress levels\n",
    "stress_metrics['stress_category'] = pd.cut(\n",
    "    stress_metrics['stormwater_stress_score'],\n",
    "    bins=[0, 0.5, 1, 1.5, 2],\n",
    "    labels=['Low', 'Moderate', 'High', 'Severe']\n",
    ")\n",
    "\n",
    "print(\"üö® STORMWATER STRESS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total stations analyzed: {len(stress_metrics)}\")\n",
    "print(f\"\\nStress Level Distribution:\")\n",
    "print(stress_metrics['stress_category'].value_counts().to_string())\n",
    "\n",
    "# Identify high stress stations\n",
    "high_stress = stress_metrics[stress_metrics['stormwater_stress_score'] > 1]\n",
    "print(f\"\\n‚ö†Ô∏è Stations with high stormwater stress: {len(high_stress)}\")\n",
    "print(f\"Percentage of stations with high stress: {len(high_stress)/len(stress_metrics)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stormwater stress visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Conductivity vs TDS Correlation',\n",
    "        'Stress Score Distribution',\n",
    "        'Top 15 Stressed Stations',\n",
    "        'Stress by Watershed'\n",
    "    ),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'histogram'}],\n",
    "           [{'type': 'bar'}, {'type': 'box'}]]\n",
    ")\n",
    "\n",
    "# 1. Conductivity vs TDS scatter\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=stress_metrics['Specific_Conductivity_Numeric_mean'],\n",
    "        y=stress_metrics['Total_Dissolved_Solids_Numeric_mean'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=stress_metrics['stormwater_stress_score'],\n",
    "            colorscale='Reds',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title='Stress', x=0.45, y=0.85, len=0.3)\n",
    "        ),\n",
    "        text=stress_metrics['Station_ID'],\n",
    "        hovertemplate='Station: %{text}<br>Cond: %{x:.0f}<br>TDS: %{y:.0f}'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "# Add threshold lines\n",
    "fig.add_hline(y=500, line_dash=\"dash\", line_color=\"red\", row=1, col=1)\n",
    "fig.add_vline(x=500, line_dash=\"dash\", line_color=\"red\", row=1, col=1)\n",
    "\n",
    "# 2. Stress score histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=stress_metrics['stormwater_stress_score'],\n",
    "        nbinsx=25,\n",
    "        marker_color='darkred'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Top stressed stations\n",
    "top_stressed = stress_metrics.nlargest(15, 'stormwater_stress_score')\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=top_stressed['Station_ID'],\n",
    "        y=top_stressed['stormwater_stress_score'],\n",
    "        marker=dict(\n",
    "            color=top_stressed['stormwater_stress_score'],\n",
    "            colorscale='Reds'\n",
    "        ),\n",
    "        text=top_stressed['stormwater_stress_score'].round(2),\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Stress by watershed\n",
    "watershed_stress = stress_metrics.groupby('Watershed_Name_first')['stormwater_stress_score'].apply(list)\n",
    "for watershed in watershed_stress.index[:10]:  # Top 10 watersheds\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=watershed_stress[watershed],\n",
    "            name=watershed[:15],\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=800, showlegend=False,\n",
    "                 title_text=\"<b>Stormwater Stress Analysis Dashboard</b>\",\n",
    "                 title_font_size=18)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Conductivity (¬µS/cm)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"TDS (mg/L)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Stress Score\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Station ID\", tickangle=45, row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Stress Score\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Watershed\", tickangle=45, row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Stress Score\", row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Water Quality Instability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate instability metrics\n",
    "instability_metrics = df.groupby('Station_ID').agg({\n",
    "    'Dissolved_Oxygen_Numeric': ['mean', 'std', 'min', 'max', 'count'],\n",
    "    'pH_Level_Numeric': ['mean', 'std', 'min', 'max'],\n",
    "    'Latitude': 'first',\n",
    "    'Longitude': 'first',\n",
    "    'Watershed_Name': 'first'\n",
    "}).round(2)\n",
    "\n",
    "instability_metrics.columns = ['_'.join(col).strip() for col in instability_metrics.columns.values]\n",
    "instability_metrics = instability_metrics.reset_index()\n",
    "\n",
    "# Calculate coefficient of variation (instability measure)\n",
    "instability_metrics['do_cv'] = (\n",
    "    instability_metrics['Dissolved_Oxygen_Numeric_std'] / \n",
    "    instability_metrics['Dissolved_Oxygen_Numeric_mean']\n",
    ") * 100\n",
    "\n",
    "instability_metrics['ph_cv'] = (\n",
    "    instability_metrics['pH_Level_Numeric_std'] / \n",
    "    instability_metrics['pH_Level_Numeric_mean']\n",
    ") * 100\n",
    "\n",
    "# pH and DO ranges\n",
    "instability_metrics['ph_range'] = (\n",
    "    instability_metrics['pH_Level_Numeric_max'] - \n",
    "    instability_metrics['pH_Level_Numeric_min']\n",
    ")\n",
    "\n",
    "instability_metrics['do_range'] = (\n",
    "    instability_metrics['Dissolved_Oxygen_Numeric_max'] - \n",
    "    instability_metrics['Dissolved_Oxygen_Numeric_min']\n",
    ")\n",
    "\n",
    "# Count critical events\n",
    "critical_events = df.groupby('Station_ID').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'do_critical': (x['Dissolved_Oxygen_Numeric'] < 5).sum(),\n",
    "        'ph_low': (x['pH_Level_Numeric'] < 6.5).sum(),\n",
    "        'ph_high': (x['pH_Level_Numeric'] > 8.5).sum()\n",
    "    })\n",
    ")\n",
    "\n",
    "instability_metrics = instability_metrics.merge(critical_events, on='Station_ID')\n",
    "\n",
    "# Calculate instability score\n",
    "instability_metrics['instability_score'] = (\n",
    "    instability_metrics['do_cv'].fillna(0) / 20 +\n",
    "    instability_metrics['ph_cv'].fillna(0) / 10 +\n",
    "    instability_metrics['ph_range'] / 2\n",
    ").clip(0, 5)\n",
    "\n",
    "print(\"üåä WATER QUALITY INSTABILITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Stations with DO < 5 mg/L events: {(instability_metrics['do_critical'] > 0).sum()}\")\n",
    "print(f\"Stations with pH violations: {((instability_metrics['ph_low'] > 0) | (instability_metrics['ph_high'] > 0)).sum()}\")\n",
    "print(f\"Average DO coefficient of variation: {instability_metrics['do_cv'].mean():.1f}%\")\n",
    "print(f\"Average pH coefficient of variation: {instability_metrics['ph_cv'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instability visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=(\n",
    "        'DO Variability (CV)',\n",
    "        'pH Variability (CV)',\n",
    "        'DO vs pH Instability',\n",
    "        'Critical DO Events',\n",
    "        'pH Violations',\n",
    "        'Instability Score Distribution'\n",
    "    ),\n",
    "    specs=[[{'type': 'histogram'}, {'type': 'histogram'}, {'type': 'scatter'}],\n",
    "           [{'type': 'bar'}, {'type': 'bar'}, {'type': 'histogram'}]]\n",
    ")\n",
    "\n",
    "# 1. DO CV histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=instability_metrics['do_cv'].dropna(),\n",
    "        nbinsx=25,\n",
    "        marker_color='blue'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. pH CV histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=instability_metrics['ph_cv'].dropna(),\n",
    "        nbinsx=25,\n",
    "        marker_color='green'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. DO vs pH instability scatter\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=instability_metrics['do_cv'],\n",
    "        y=instability_metrics['ph_cv'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=instability_metrics['instability_score'],\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title='Score', x=1.02, y=0.85, len=0.3)\n",
    "        ),\n",
    "        text=instability_metrics['Station_ID'],\n",
    "        hovertemplate='Station: %{text}<br>DO CV: %{x:.1f}%<br>pH CV: %{y:.1f}%'\n",
    "    ),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "# 4. Critical DO events\n",
    "top_do_critical = instability_metrics.nlargest(15, 'do_critical')\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=top_do_critical['Station_ID'],\n",
    "        y=top_do_critical['do_critical'],\n",
    "        marker_color='red',\n",
    "        text=top_do_critical['do_critical'],\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 5. pH violations\n",
    "instability_metrics['ph_violations'] = instability_metrics['ph_low'] + instability_metrics['ph_high']\n",
    "top_ph_violations = instability_metrics.nlargest(15, 'ph_violations')\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=top_ph_violations['Station_ID'],\n",
    "        y=top_ph_violations['ph_violations'],\n",
    "        marker_color='purple',\n",
    "        text=top_ph_violations['ph_violations'],\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# 6. Instability score distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=instability_metrics['instability_score'],\n",
    "        nbinsx=25,\n",
    "        marker_color='orange'\n",
    "    ),\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "fig.update_layout(height=700, showlegend=False,\n",
    "                 title_text=\"<b>Water Quality Instability Analysis</b>\",\n",
    "                 title_font_size=18)\n",
    "\n",
    "fig.update_xaxes(title_text=\"CV (%)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"CV (%)\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"DO CV (%)\", row=1, col=3)\n",
    "fig.update_yaxes(title_text=\"pH CV (%)\", row=1, col=3)\n",
    "fig.update_xaxes(title_text=\"Station\", tickangle=45, row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Station\", tickangle=45, row=2, col=2)\n",
    "fig.update_xaxes(title_text=\"Instability Score\", row=2, col=3)\n",
    "fig.update_yaxes(title_text=\"Critical Events\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Violations\", row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Temporal and Seasonal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal analysis\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=(\n",
    "        'DO by Season',\n",
    "        'pH by Season',\n",
    "        'Temperature by Season',\n",
    "        'Monthly DO Trends',\n",
    "        'Monthly Conductivity',\n",
    "        'Yearly Trends'\n",
    "    ),\n",
    "    specs=[[{'type': 'box'}, {'type': 'box'}, {'type': 'box'}],\n",
    "           [{'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}]]\n",
    ")\n",
    "\n",
    "# Season order\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "\n",
    "# 1-3. Seasonal boxplots\n",
    "for season in season_order:\n",
    "    season_data = df[df['Season_Name'] == season]\n",
    "    \n",
    "    # DO by season\n",
    "    fig.add_trace(\n",
    "        go.Box(y=season_data['Dissolved_Oxygen_Numeric'], name=season, showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # pH by season\n",
    "    fig.add_trace(\n",
    "        go.Box(y=season_data['pH_Level_Numeric'], name=season, showlegend=False),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Temperature by season\n",
    "    fig.add_trace(\n",
    "        go.Box(y=season_data['Temperature_C_Numeric'], name=season, showlegend=False),\n",
    "        row=1, col=3\n",
    "    )\n",
    "\n",
    "# 4. Monthly DO trends\n",
    "monthly_do = df.groupby('Month')['Dissolved_Oxygen_Numeric'].agg(['mean', 'std'])\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=month_names,\n",
    "        y=monthly_do['mean'],\n",
    "        mode='lines+markers',\n",
    "        error_y=dict(type='data', array=monthly_do['std']),\n",
    "        line=dict(color='blue', width=2)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_hline(y=5, line_dash=\"dash\", line_color=\"red\", row=2, col=1)\n",
    "\n",
    "# 5. Monthly Conductivity\n",
    "monthly_cond = df.groupby('Month')['Specific_Conductivity_Numeric'].agg(['mean', 'std'])\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=month_names,\n",
    "        y=monthly_cond['mean'],\n",
    "        mode='lines+markers',\n",
    "        error_y=dict(type='data', array=monthly_cond['std']),\n",
    "        line=dict(color='orange', width=2)\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "fig.add_hline(y=500, line_dash=\"dash\", line_color=\"red\", row=2, col=2)\n",
    "\n",
    "# 6. Yearly trends\n",
    "yearly_avg = df.groupby('Year')[['Dissolved_Oxygen_Numeric', 'pH_Level_Numeric', 'Specific_Conductivity_Numeric']].mean()\n",
    "for param, color, name in [('Dissolved_Oxygen_Numeric', 'blue', 'DO'),\n",
    "                           ('pH_Level_Numeric', 'green', 'pH'),\n",
    "                           ('Specific_Conductivity_Numeric', 'orange', 'Conductivity')]:\n",
    "    # Normalize for comparison\n",
    "    normalized = (yearly_avg[param] - yearly_avg[param].mean()) / yearly_avg[param].std()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=yearly_avg.index,\n",
    "            y=normalized,\n",
    "            mode='lines+markers',\n",
    "            name=name,\n",
    "            line=dict(color=color, width=2)\n",
    "        ),\n",
    "        row=2, col=3\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=700, showlegend=True,\n",
    "                 title_text=\"<b>Temporal and Seasonal Patterns</b>\",\n",
    "                 title_font_size=18)\n",
    "\n",
    "fig.update_yaxes(title_text=\"DO (mg/L)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"pH\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Temp (¬∞C)\", row=1, col=3)\n",
    "fig.update_xaxes(title_text=\"Month\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"DO (mg/L)\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Month\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Conductivity\", row=2, col=2)\n",
    "fig.update_xaxes(title_text=\"Year\", row=2, col=3)\n",
    "fig.update_yaxes(title_text=\"Normalized Value\", row=2, col=3)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Conservation Hotspot Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all metrics to identify hotspots\n",
    "hotspots = stress_metrics[['Station_ID', 'Latitude_first', 'Longitude_first', \n",
    "                           'stormwater_stress_score', 'Watershed_Name_first']].copy()\n",
    "hotspots.columns = ['Station_ID', 'Latitude', 'Longitude', 'stress_score', 'Watershed']\n",
    "\n",
    "# Add instability score\n",
    "hotspots = hotspots.merge(\n",
    "    instability_metrics[['Station_ID', 'instability_score', 'do_critical', 'ph_violations']],\n",
    "    on='Station_ID', how='left'\n",
    ")\n",
    "\n",
    "# Calculate persistence score\n",
    "problem_counts = df.groupby('Station_ID').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'total_samples': len(x),\n",
    "        'problem_events': (\n",
    "            (x['Dissolved_Oxygen_Numeric'] < 5).sum() +\n",
    "            ((x['pH_Level_Numeric'] < 6.5) | (x['pH_Level_Numeric'] > 8.5)).sum() +\n",
    "            (x['Specific_Conductivity_Numeric'] > 500).sum() +\n",
    "            (x['Total_Dissolved_Solids_Numeric'] > 500).sum()\n",
    "        )\n",
    "    })\n",
    ")\n",
    "\n",
    "problem_counts['persistence_score'] = (problem_counts['problem_events'] / problem_counts['total_samples']).clip(0, 1)\n",
    "hotspots = hotspots.merge(problem_counts[['persistence_score']], on='Station_ID', how='left')\n",
    "\n",
    "# Calculate composite hotspot score (weighted average)\n",
    "hotspots['hotspot_score'] = (\n",
    "    hotspots['stress_score'].fillna(0) * 0.4 +\n",
    "    hotspots['instability_score'].fillna(0) * 0.3 +\n",
    "    hotspots['persistence_score'].fillna(0) * 0.3\n",
    ") * 100\n",
    "\n",
    "# Categorize priority levels\n",
    "hotspots['priority'] = pd.cut(\n",
    "    hotspots['hotspot_score'],\n",
    "    bins=[0, 25, 50, 75, 100],\n",
    "    labels=['Low', 'Medium', 'High', 'Critical']\n",
    ")\n",
    "\n",
    "print(\"üéØ CONSERVATION HOTSPOT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"Priority Distribution:\")\n",
    "print(hotspots['priority'].value_counts().to_string())\n",
    "print(f\"\\nAverage hotspot score: {hotspots['hotspot_score'].mean():.1f}/100\")\n",
    "print(f\"Stations requiring immediate attention (Critical): {(hotspots['priority'] == 'Critical').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top conservation priorities\n",
    "print(\"\\nüèÜ TOP 20 CONSERVATION PRIORITY STATIONS\")\n",
    "print(\"=\"*60)\n",
    "top20 = hotspots.nlargest(20, 'hotspot_score')\n",
    "\n",
    "for idx, (_, row) in enumerate(top20.iterrows(), 1):\n",
    "    print(f\"{idx:2}. {row['Station_ID']:15} Score: {row['hotspot_score']:6.1f} Priority: {row['priority']:8} Watershed: {row['Watershed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Interactive Conservation Priority Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive Plotly map\n",
    "fig = px.scatter_mapbox(\n",
    "    hotspots,\n",
    "    lat='Latitude',\n",
    "    lon='Longitude',\n",
    "    color='hotspot_score',\n",
    "    size='hotspot_score',\n",
    "    color_continuous_scale='RdYlGn_r',\n",
    "    size_max=15,\n",
    "    zoom=7,\n",
    "    mapbox_style='carto-positron',\n",
    "    title='<b>Water Quality Hotspots - Conservation Priority Map</b>',\n",
    "    hover_name='Station_ID',\n",
    "    hover_data={\n",
    "        'priority': True,\n",
    "        'stress_score': ':.2f',\n",
    "        'instability_score': ':.2f',\n",
    "        'persistence_score': ':.2f',\n",
    "        'hotspot_score': ':.1f',\n",
    "        'Watershed': True\n",
    "    },\n",
    "    labels={'hotspot_score': 'Hotspot Score'},\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    mapbox=dict(\n",
    "        center=dict(\n",
    "            lat=hotspots['Latitude'].mean(),\n",
    "            lon=hotspots['Longitude'].mean()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed Folium map with layers\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "# Initialize map\n",
    "m = folium.Map(\n",
    "    location=[hotspots['Latitude'].mean(), hotspots['Longitude'].mean()],\n",
    "    zoom_start=8,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Add tile layers\n",
    "folium.TileLayer('CartoDB positron', name='Light Map').add_to(m)\n",
    "folium.TileLayer('CartoDB dark_matter', name='Dark Map').add_to(m)\n",
    "\n",
    "# Color function\n",
    "def get_color(score):\n",
    "    if score >= 75: return 'red'\n",
    "    elif score >= 50: return 'orange'\n",
    "    elif score >= 25: return 'yellow'\n",
    "    else: return 'green'\n",
    "\n",
    "# Add markers for each station\n",
    "for idx, row in hotspots.iterrows():\n",
    "    popup_text = f\"\"\"\n",
    "    <div style=\"width: 200px;\">\n",
    "        <b>Station: {row['Station_ID']}</b><br>\n",
    "        <b>Priority: {row['priority']}</b><br>\n",
    "        Hotspot Score: {row['hotspot_score']:.1f}/100<br>\n",
    "        <hr>\n",
    "        Stress: {row['stress_score']:.2f}<br>\n",
    "        Instability: {row['instability_score']:.2f}<br>\n",
    "        Persistence: {row['persistence_score']:.2f}<br>\n",
    "        Watershed: {row['Watershed']}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['Latitude'], row['Longitude']],\n",
    "        radius=5 + row['hotspot_score'] / 10,\n",
    "        popup=folium.Popup(popup_text, max_width=300),\n",
    "        tooltip=f\"{row['Station_ID']}: {row['hotspot_score']:.1f}\",\n",
    "        color=get_color(row['hotspot_score']),\n",
    "        fillColor=get_color(row['hotspot_score']),\n",
    "        fillOpacity=0.7,\n",
    "        weight=2\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add heatmap layer\n",
    "heat_data = [[row['Latitude'], row['Longitude'], row['hotspot_score']] \n",
    "             for idx, row in hotspots.iterrows()]\n",
    "plugins.HeatMap(heat_data, name='Hotspot Heatmap', radius=15).add_to(m)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Display map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive dashboard\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=3,\n",
    "    subplot_titles=(\n",
    "        'Priority Distribution',\n",
    "        'Top 10 Hotspots',\n",
    "        'Score Components',\n",
    "        'Hotspots by Watershed',\n",
    "        'Stress vs Instability',\n",
    "        'Problem Events Distribution',\n",
    "        'Parameter Correlations',\n",
    "        'Monthly Violations',\n",
    "        'Action Priority Matrix'\n",
    "    ),\n",
    "    specs=[[{'type': 'pie'}, {'type': 'bar'}, {'type': 'bar'}],\n",
    "           [{'type': 'box'}, {'type': 'scatter'}, {'type': 'histogram'}],\n",
    "           [{'type': 'heatmap'}, {'type': 'scatter'}, {'type': 'scatter'}]]\n",
    ")\n",
    "\n",
    "# 1. Priority distribution pie\n",
    "priority_counts = hotspots['priority'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=priority_counts.index,\n",
    "        values=priority_counts.values,\n",
    "        marker=dict(colors=['green', 'yellow', 'orange', 'red']),\n",
    "        hole=0.3\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Top 10 hotspots\n",
    "top10 = hotspots.nlargest(10, 'hotspot_score')\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=top10['Station_ID'],\n",
    "        y=top10['hotspot_score'],\n",
    "        marker=dict(color=top10['hotspot_score'], colorscale='RdYlGn_r'),\n",
    "        text=top10['hotspot_score'].round(1),\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Score components\n",
    "components = ['stress_score', 'instability_score', 'persistence_score']\n",
    "component_means = [hotspots[c].mean() for c in components]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=['Stormwater\\nStress', 'Water Quality\\nInstability', 'Problem\\nPersistence'],\n",
    "        y=component_means,\n",
    "        marker_color=['red', 'blue', 'green'],\n",
    "        text=[f'{m:.2f}' for m in component_means],\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "# 4. Hotspots by watershed\n",
    "top_watersheds = hotspots['Watershed'].value_counts().head(8).index\n",
    "for watershed in top_watersheds:\n",
    "    watershed_scores = hotspots[hotspots['Watershed'] == watershed]['hotspot_score']\n",
    "    fig.add_trace(\n",
    "        go.Box(y=watershed_scores, name=watershed[:12], showlegend=False),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# 5. Stress vs Instability\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=hotspots['stress_score'],\n",
    "        y=hotspots['instability_score'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=hotspots['hotspot_score'],\n",
    "            colorscale='RdYlGn_r',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title='Score', x=0.68, y=0.5, len=0.25)\n",
    "        ),\n",
    "        text=hotspots['Station_ID'],\n",
    "        hovertemplate='%{text}<br>Stress: %{x:.2f}<br>Instability: %{y:.2f}'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# 6. Problem events distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=hotspots['do_critical'] + hotspots['ph_violations'],\n",
    "        nbinsx=20,\n",
    "        marker_color='darkred'\n",
    "    ),\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "# 7. Parameter correlations\n",
    "corr_params = ['stress_score', 'instability_score', 'persistence_score', 'hotspot_score']\n",
    "corr_matrix = hotspots[corr_params].corr()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=corr_matrix.values,\n",
    "        x=['Stress', 'Instability', 'Persistence', 'Hotspot'],\n",
    "        y=['Stress', 'Instability', 'Persistence', 'Hotspot'],\n",
    "        colorscale='RdBu',\n",
    "        zmid=0,\n",
    "        text=corr_matrix.values.round(2),\n",
    "        texttemplate='%{text}'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# 8. Monthly violations\n",
    "monthly_violations = df.groupby('Month').apply(\n",
    "    lambda x: (\n",
    "        (x['Dissolved_Oxygen_Numeric'] < 5).sum() +\n",
    "        ((x['pH_Level_Numeric'] < 6.5) | (x['pH_Level_Numeric'] > 8.5)).sum()\n",
    "    ) / len(x) * 100\n",
    ")\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=month_names,\n",
    "        y=monthly_violations.values,\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='red', width=2),\n",
    "        marker=dict(size=8)\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "# 9. Action priority matrix\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=hotspots['stress_score'],\n",
    "        y=hotspots['persistence_score'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            color=hotspots['priority'].map({'Low': 0, 'Medium': 1, 'High': 2, 'Critical': 3}),\n",
    "            colorscale=['green', 'yellow', 'orange', 'red'],\n",
    "            showscale=False\n",
    "        ),\n",
    "        text=hotspots['Station_ID'],\n",
    "        hovertemplate='%{text}<br>Stress: %{x:.2f}<br>Persistence: %{y:.2f}'\n",
    "    ),\n",
    "    row=3, col=3\n",
    ")\n",
    "\n",
    "# Add quadrant lines\n",
    "fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"gray\", row=3, col=3)\n",
    "fig.add_vline(x=1, line_dash=\"dash\", line_color=\"gray\", row=3, col=3)\n",
    "\n",
    "fig.update_layout(height=1000, showlegend=False,\n",
    "                 title_text=\"<b>Conservation Priority Dashboard</b>\",\n",
    "                 title_font_size=20)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export hotspot analysis results\n",
    "output_file = '/mnt/user-data/outputs/conservation_hotspots.csv'\n",
    "hotspots.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Hotspot analysis results saved to: {output_file}\")\n",
    "\n",
    "# Save summary report\n",
    "report_file = '/mnt/user-data/outputs/conservation_report.txt'\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(\"WATERSHED CONSERVATION PRIORITY REPORT\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    f.write(f\"Analysis Date: {datetime.now()}\\n\")\n",
    "    f.write(f\"Total Stations Analyzed: {len(hotspots)}\\n\\n\")\n",
    "    f.write(\"Priority Distribution:\\n\")\n",
    "    f.write(hotspots['priority'].value_counts().to_string())\n",
    "    f.write(\"\\n\\nTop 20 Conservation Priorities:\\n\")\n",
    "    top20_report = hotspots.nlargest(20, 'hotspot_score')[['Station_ID', 'hotspot_score', 'priority', 'Watershed']]\n",
    "    f.write(top20_report.to_string(index=False))\n",
    "    \n",
    "print(f\"‚úÖ Summary report saved to: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Findings & Recommendations\n",
    "\n",
    "### Critical Findings:\n",
    "1. **Hotspot Distribution**: Analysis of priority levels across all monitoring stations\n",
    "2. **Stormwater Stress**: Stations showing elevated conductivity and TDS from runoff\n",
    "3. **Ecosystem Instability**: Areas with high variability in DO and pH\n",
    "4. **Persistent Problems**: Stations with repeated water quality violations\n",
    "\n",
    "### Recommendations:\n",
    "1. **Immediate Action**: Focus land preservation on Critical priority stations\n",
    "2. **Green Infrastructure**: Implement stormwater controls in high-stress watersheds\n",
    "3. **Monitoring Enhancement**: Increase frequency at unstable locations\n",
    "4. **Community Engagement**: Partner with communities near hotspots\n",
    "\n",
    "### Next Steps:\n",
    "- Overlay environmental justice data\n",
    "- Add impervious surface analysis\n",
    "- Incorporate climate projections\n",
    "- Develop watershed-specific action plans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
